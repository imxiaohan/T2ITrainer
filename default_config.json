{
    "script": "train_flux_lora_ui_kontext.py",
    "script_choices": [
        "train_flux_lora_ui_kontext.py",
        "train_flux_lora_ui_with_mask.py",
        "train_flux_lora_ui.py"
    ],
    "output_dir": "",
    "save_name": "",
    "pretrained_model_name_or_path": "./flux_models/kontext",
    "train_data_dir": "",
    "resume_from_checkpoint": null,
    "model_path": null,
    "report_to": "wandb",
    "rank": 16,
    "train_batch_size": 1,
    "repeats": 1,
    "gradient_accumulation_steps": 1,
    "mixed_precision": "bf16",
    "gradient_checkpointing": true,
    "optimizer": "adamw",
    "lr_scheduler": "constant",
    "learning_rate": 0.0001,
    "lr_warmup_steps": 0,
    "seed": 4321,
    "num_train_epochs": 5,
    "save_model_epochs": 1,
    "validation_epochs": 1,
    "skip_epoch": 0,
    "skip_step": 0,
    "validation_ratio": 0.1,
    "recreate_cache": false,
    "caption_dropout": 0.1,
    "config_path": "default_config.json",
    "resolution": "512",
    "resolution_choices": ["512", "256", "1024"],
    "use_debias": false,
    "snr_gamma": 0,
    "cosine_restarts": 1,
    "max_time_steps": 0,
    "blocks_to_swap": 0,
    "mask_dropout": 0,
    "reg_ratio": 0.0,
    "reg_timestep": 0
} 